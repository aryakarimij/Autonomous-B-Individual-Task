{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Lab_01\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 0) Setup & Imports\n"]}, {"cell_type": "code", "metadata": {}, "source": ["import sys, os, math, random, datetime\n", "from pathlib import Path\n", "import torch, torch.nn as nn, torch.nn.functional as F\n", "from torch.utils.data import DataLoader\n", "from torchvision import datasets, transforms\n", "import matplotlib.pyplot as plt\n", "\n", "base = Path.cwd()\n", "(base/'reports/images').mkdir(parents=True, exist_ok=True)\n", "\n", "def savefig(name):\n", "    plt.savefig(base/'reports'/'images'/name, bbox_inches='tight'); plt.close()\n", "\n", "torch.manual_seed(42); random.seed(42)\n", "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "device"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Tensors & Arrays\n", "Explain N (batch), C (channels), H/W (height/width). Show a quick shape check."]}, {"cell_type": "code", "metadata": {}, "source": ["x = torch.randn(32,1,28,28)\n", "y = torch.randn(16,3,64,64)\n", "print('grayscale batch:', x.shape, '| RGB batch:', y.shape)"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2\u20133) FFNN + Training Loop & Backprop\n", "Train \u22653 epochs on MNIST. Plot loss, report test accuracy."]}, {"cell_type": "code", "metadata": {}, "source": ["class FFNN(nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.net = nn.Sequential(nn.Flatten(), nn.Linear(28*28,128), nn.ReLU(), nn.Linear(128,10))\n", "    def forward(self,x): return self.net(x)\n", "\n", "tfm = transforms.ToTensor()\n", "train_ds = datasets.MNIST('./data', train=True, download=True, transform=tfm)\n", "test_ds  = datasets.MNIST('./data', train=False, download=True, transform=tfm)\n", "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n", "test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False)\n", "\n", "def accuracy(model, loader):\n", "    model.eval(); c=t=0\n", "    with torch.no_grad():\n", "        for X,y in loader:\n", "            X,y = X.to(device), y.to(device)\n", "            p = model(X).argmax(1)\n", "            c += (p==y).sum().item(); t += y.size(0)\n", "    return c/t\n", "\n", "ffnn = FFNN().to(device)\n", "opt = torch.optim.SGD(ffnn.parameters(), lr=0.01, momentum=0.9)\n", "crit = nn.CrossEntropyLoss()\n", "losses=[]\n", "for ep in range(3):\n", "    ffnn.train(); run=0.0\n", "    for X,y in train_loader:\n", "        X,y = X.to(device), y.to(device)\n", "        opt.zero_grad(); loss = crit(ffnn(X), y); loss.backward(); opt.step()\n", "        run += loss.item()\n", "    losses.append(run/len(train_loader))\n", "    print(f'[FFNN] epoch {ep+1} loss={losses[-1]:.4f}')\n", "import matplotlib.pyplot as plt\n", "plt.figure(); plt.plot(losses); plt.title('FFNN Training Loss'); plt.xlabel('epoch'); plt.ylabel('loss'); savefig('mlp_loss.png')\n", "print('[FFNN] test accuracy:', round(accuracy(ffnn,test_loader)*100,2),'%')"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3b) Gradient Check (finite differences)\n", "Verify autograd vs. numerical gradient on a tiny MLP."]}, {"cell_type": "code", "metadata": {}, "source": ["torch.manual_seed(0)\n", "tiny = nn.Sequential(nn.Flatten(), nn.Linear(28*28,5), nn.ReLU(), nn.Linear(5,3)).to(device)\n", "xb = torch.randn(4,1,28,28, device=device); yb = torch.tensor([0,1,2,1], device=device)\n", "tiny.zero_grad(); L = nn.CrossEntropyLoss()(tiny(xb), yb); L.backward()\n", "anal = tiny[1].weight.grad.detach().view(-1).cpu()\n", "eps=1e-4; num = torch.zeros_like(anal)\n", "w = tiny[1].weight.data.view(-1)\n", "for i in range(min(50, w.numel())):\n", "    old = w[i].item()\n", "    w[i] = old + eps; Lp = nn.CrossEntropyLoss()(tiny(xb), yb).item()\n", "    w[i] = old - eps; Lm = nn.CrossEntropyLoss()(tiny(xb), yb).item()\n", "    w[i] = old; num[i] = (Lp-Lm)/(2*eps)\n", "print('Gradient check \u2014 mean |analytical\u2212numerical| over 50 params:', float((anal[:50]-num[:50]).abs().mean()))"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) CNN baseline vs FFNN + filter visualization"]}, {"cell_type": "code", "metadata": {}, "source": ["class SmallCNN(nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.c1 = nn.Conv2d(1,8,3,padding=1)\n", "        self.c2 = nn.Conv2d(8,16,3,padding=1)\n", "        self.fc = nn.Linear(16*7*7,10)\n", "    def forward(self,x):\n", "        x = F.relu(self.c1(x)); x = F.max_pool2d(x,2)\n", "        x = F.relu(self.c2(x)); x = F.max_pool2d(x,2)\n", "        x = torch.flatten(x,1); return self.fc(x)\n", "\n", "cnn = SmallCNN().to(device)\n", "opt = torch.optim.SGD(cnn.parameters(), lr=0.05, momentum=0.9)\n", "losses=[]\n", "for ep in range(3):\n", "    cnn.train(); run=0.0\n", "    for X,y in train_loader:\n", "        X,y = X.to(device), y.to(device)\n", "        opt.zero_grad(); loss = nn.CrossEntropyLoss()(cnn(X), y); loss.backward(); opt.step()\n", "        run += loss.item()\n", "    losses.append(run/len(train_loader))\n", "    print(f'[CNN] epoch {ep+1} loss={losses[-1]:.4f}')\n", "plt.figure(); plt.plot(losses); plt.title('CNN Training Loss'); plt.xlabel('epoch'); plt.ylabel('loss'); savefig('cnn_loss.png')\n", "print('[CNN] test accuracy:', round((lambda m,ldr: (sum((m(X.to(device)).argmax(1)==y.to(device)).sum().item() for X,y in ldr))/sum(y.size(0) for _,y in ldr))(cnn,test_loader)*100,2),'%')\n", "\n", "# Filter visualization\n", "with torch.no_grad(): w = cnn.c1.weight.detach().cpu()\n", "fig,axs = plt.subplots(1,w.shape[0], figsize=(w.shape[0]*2,2))\n", "for i,ax in enumerate(axs): ax.imshow(w[i,0], cmap='gray'); ax.axis('off')\n", "fig.suptitle('Conv1 filters'); savefig('conv1_filters.png')"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5) Hyperparameter sweep (learning rate)\n", "Compare LR \u2208 {0.005, 0.05, 0.5} for 2 quick epochs."]}, {"cell_type": "code", "metadata": {}, "source": ["def train_cnn_lr(lr):\n", "    m=SmallCNN().to(device); o=torch.optim.SGD(m.parameters(), lr=lr, momentum=0.9)\n", "    L=[]\n", "    for ep in range(2):\n", "        m.train(); run=0.0\n", "        for X,y in train_loader:\n", "            X,y = X.to(device), y.to(device)\n", "            o.zero_grad(); loss = nn.CrossEntropyLoss()(m(X), y); loss.backward(); o.step(); run += loss.item()\n", "        L.append(run/len(train_loader))\n", "    return L\n", "hist = {lr: train_cnn_lr(lr) for lr in (0.005, 0.05, 0.5)}\n", "plt.figure()\n", "for lr,L in hist.items(): plt.plot(L, label=f'lr={lr}')\n", "plt.legend(); plt.title('LR Sweep (loss)'); plt.xlabel('epoch'); plt.ylabel('loss'); savefig('lr_loss.png')"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6) Convolution arithmetic (formula + sanity)\n", "Formula:  \n", "\\(H' = \\lfloor (H+2p-k)/s \\rfloor + 1,\\ W' = \\lfloor (W+2p-k)/s \\rfloor + 1\\)"]}, {"cell_type": "code", "metadata": {}, "source": ["def conv2d_out(H,W,k=3,s=1,p=0): return (H+2*p-k)//s + 1, (W+2*p-k)//s + 1\n", "print('28x28, k=3,s=1,p=1 ->', conv2d_out(28,28,3,1,1))\n", "x = torch.zeros(1,1,64,64); y = nn.Conv2d(1,1,3,2,1)(x); print('Torch says:', tuple(y.shape[-2:]))"], "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}